# ğŸ“œ OCR Manuscrit - MÃ©moires de Guerre 1914-1918

Digitalisation d'un manuscrit familial de ~500 pages en utilisant un Vision-Language Model fine-tunÃ© sur l'Ã©criture spÃ©cifique de l'auteur.

## ğŸ›  Stack technique

| Composant | Technologie |
|-----------|-------------|
| ModÃ¨le | [LFM2.5-VL-1.6B](https://huggingface.co/LiquidAI/LFM2.5-VL-1.6B) (Liquid AI) |
| Fine-tuning | LoRA + TRL (SFTTrainer) |
| Segmentation | OpenCV (projection horizontale) |
| Conversion PDF | pdf2image + Poppler |
| Training | Google Colab (A100) |

## ğŸ“ Structure du projet

```
â”œâ”€â”€ sft/
â”‚   â”œâ”€â”€ SFT_LFM2_5_VL_1_6B.ipynb              # Notebook d'entraÃ®nement (Colab)
â”‚   â”œâ”€â”€ training_data/
â”‚   â”‚   â”œâ”€â”€ extract_training_data.py          # Segmentation pages â†’ lignes
â”‚   â”‚   â””â”€â”€ augment_training_data.py          # Augmentation (rotation et luminositÃ©)
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ test_LFM2_5_base_model.py         # Test du modÃ¨le de base
â”‚       â””â”€â”€ test_SFT_LFM2_VL_1_6B.py          # Test du modÃ¨le fine-tunÃ©
â”œâ”€â”€ models/                                   # (non versionnÃ©) ModÃ¨le et Adapters
â””â”€â”€ data/                                     # (non versionnÃ©) Dataset et transcriptions (jsonl)
â””â”€â”€ sample/                     
    â”œâ”€â”€ lines_sample/                         # Sample des lignes PNG de la page 6
    â”œâ”€â”€ page_006.png                          # Exemple de PNG d'une page
    â””â”€â”€ transcription_sample.png              # Sample des transcriptions des lignes augmentÃ©es
```

## ğŸ”„ Pipeline

```
PDF â”€â”€â†’ Images (300 DPI) â”€â”€â†’ Lignes (OpenCV) â”€â”€â†’ Fine-tuning LoRA â”€â”€â†’ InfÃ©rence
```

1. **Conversion** : PDF â†’ PNG haute rÃ©solution
2. **Segmentation** : DÃ©coupage des pages en lignes individuelles
3. **LabÃ©lisation** : Transcription manuelle des lignes
4. **Augmentation** : Variations de luminositÃ© pour robustesse
5. **Fine-tuning** : EntraÃ®nement LoRA sur l'Ã©criture manuscrite
6. **InfÃ©rence** : OCR batch ligne par ligne

## ğŸ“Š RÃ©sultats

**Dataset** : 2000 lignes labÃ©lisÃ©es (avec augmentation)

| Epoch | Training Loss | Validation Loss | Token Accuracy |
|-------|---------------|-----------------|----------------|
| 1 | 0.55 | 0.50 | 89.4% |
| 3 | 0.18 | 0.27 | 94.4% |
| 5 | 0.11 | 0.22 | **95.7%** |

## â™»ï¸ Mettre Ã  jour le fine-tuning

### 1. Installation

```bash
pip install torch transformers peft trl pillow opencv-python pdf2image
```

### 2. PrÃ©parer les donnÃ©es d'entraÃ®nement

```bash
# 1. Segmenter les pages en lignes
python sft/training_data/extract_training_data.py

# 2. LabÃ©liser manuellement â†’ transcription.jsonl
# Format : {"image": "page_001_line_001.png", "text": "transcription ici"}

# 3. Augmenter le dataset (variations de luminositÃ©)
python sft/training_data/augment_training_data.py
```

### 3. Fine-tuning (Google Colab)

1. Uploader `sft/SFT_LFM2_5_VL_1_6B.ipynb` sur Colab
2. Uploader le dataset (`lines/` + `transcription_augmented.jsonl`)
3. SÃ©lectionner GPU (A100 recommandÃ©)
4. ExÃ©cuter le notebook

### 4. RÃ©cupÃ©rer le modÃ¨le fine-tunÃ©

AprÃ¨s l'entraÃ®nement, tÃ©lÃ©charger depuis Google Drive :
```
checkpoint-xxx/
â”œâ”€â”€ adapter_config.json      # Config LoRA
â””â”€â”€ adapter_model.safetensors # Poids (~14 MB)
```

Placer dans `./models/lfm25-adapter/`

### 5. InfÃ©rence locale

```bash
# TÃ©lÃ©charger le modÃ¨le de base (une seule fois)
huggingface-cli download LiquidAI/LFM2.5-VL-1.6B --local-dir ./models/lfm25-base

# Tester le modÃ¨le fine-tunÃ©
python sft/tests/test_SFT_LFM2_VL_1_6B.py
```

### 6. RÃ©-entraÃ®nement (amÃ©liorer le modÃ¨le)

```
Nouvelles donnÃ©es â†’ extract â†’ augment â†’ Colab â†’ tÃ©lÃ©charger adapter_*.safetensors
```

Seuls les fichiers `adapter_config.json` et `adapter_model.safetensors` changent (~14 MB).
Le modÃ¨le de base (~3 GB) reste identique.

## ğŸ“ Licence

Projet personnel â€” code partagÃ© Ã  titre Ã©ducatif.

---

*Projet rÃ©alisÃ© dans le cadre de la prÃ©servation d'un patrimoine familial.*